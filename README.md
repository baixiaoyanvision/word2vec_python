# word2vec_python
基于python的word2vec方法，训练语料为中文

中文语料的获取，第一种方法是去网上下载相关语料，我这里有一份复旦大学中文文本分类时用的语料模型，分为训练集（https://download.csdn.net/download/laobai1015/10431543） 和测试集（https://download.csdn.net/download/laobai1015/10431564） 两部分，约220M，包括了常用的中文词汇。训练文本的大小直接决定了算法的训练效果，如果你有更合适的语料库可以用自己的。

首先去网下载相关的语料文本，然后将其打开后另存为，注意选utf－8编码格式。
文本文件准备好，然后开始用python对此txt文档进行处理：由函数cut_txt()实现

准备好训练语料（注意训练语料文件越大越好，越大最后的训练效果越好），之后就开始写训练模型了，训练模型的代码在model_train()中实现

两个功能都以函数方式实现了，还编写主函数代码，在主函数中负责调用各个方法实现预处理和模型训练，以此做后面的相关计算。
